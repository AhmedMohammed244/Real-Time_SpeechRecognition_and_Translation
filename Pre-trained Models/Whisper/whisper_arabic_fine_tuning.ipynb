{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsZdEBMeJot-"
      },
      "source": [
        "# -- Whisper Fine-Tuning for Arabic Speech Recognition --\n",
        "\n",
        "This notebook demonstrates **fine-tuning OpenAI's Whisper model** on the **Common Voice Arabic dataset** using Hugging Face Transformers.\n",
        "\n",
        "ðŸ“Œ **Notebook Steps:**\n",
        "\n",
        "1. Install dependencies and import libraries  \n",
        "2. Load and prepare Common Voice Arabic dataset  \n",
        "3. Preprocess text (clean and normalize Arabic)  \n",
        "4. Convert audio + labels into model inputs  \n",
        "5. Define evaluation metric (Word Error Rate)  \n",
        "6. Load Whisper model and processor  \n",
        "7. Define training configuration and data collator  \n",
        "8. Train the model  \n",
        "9. Evaluate on test data  \n",
        "10. Save and reload model for inference  \n",
        "11. Transcribe sample audio from test set\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mg-N-p-zJouC"
      },
      "source": [
        "# Install Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-05-06T15:34:09.306448Z",
          "iopub.status.busy": "2025-05-06T15:34:09.305870Z",
          "iopub.status.idle": "2025-05-06T15:34:21.587886Z",
          "shell.execute_reply": "2025-05-06T15:34:21.586839Z",
          "shell.execute_reply.started": "2025-05-06T15:34:09.306416Z"
        },
        "id": "7K7r4X6nGaG_",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "5b57ad99-2358-4396-a7cf-9e97eb93b058",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.16)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.1)\n",
            "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.3.8)\n",
            "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.2.4)\n",
            "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (0.1.1)\n",
            "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2025.1.0)\n",
            "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2022.1.0)\n",
            "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\n",
            "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2022.1.0)\n",
            "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.2.0)\n",
            "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\n",
            "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.1)\n",
            "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\n",
            "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\n",
            "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\n",
            "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\n",
            "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\n",
            "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\n",
            "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\n",
            "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\n",
            "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\n",
            "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n",
            "Requirement already satisfied: jiwer in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer) (8.1.8)\n",
            "Requirement already satisfied: rapidfuzz>=3.9.7 in /usr/local/lib/python3.11/dist-packages (from jiwer) (3.13.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.12.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.16)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.1)\n",
            "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\n",
            "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\n",
            "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\n",
            "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2025.1.0)\n",
            "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2022.1.0)\n",
            "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.19.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\n",
            "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.1.0)\n",
            "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.2.0)\n",
            "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\n",
            "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n",
        "!pip install transformers\n",
        "!pip install jiwer\n",
        "!pip install evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIMVXx3cJouF"
      },
      "source": [
        "# Hugging Face Login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-06T15:17:49.612282Z",
          "iopub.status.busy": "2025-05-06T15:17:49.611660Z",
          "iopub.status.idle": "2025-05-06T15:17:50.405379Z",
          "shell.execute_reply": "2025-05-06T15:17:50.404834Z",
          "shell.execute_reply.started": "2025-05-06T15:17:49.612258Z"
        },
        "id": "eDXqXmAOJouF",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "secret_key = \"\"\n",
        "login(token = secret_key)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pKffrtIJouG"
      },
      "source": [
        "#  Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-06T15:35:06.151091Z",
          "iopub.status.busy": "2025-05-06T15:35:06.150512Z",
          "iopub.status.idle": "2025-05-06T15:35:07.810427Z",
          "shell.execute_reply": "2025-05-06T15:35:07.809672Z",
          "shell.execute_reply.started": "2025-05-06T15:35:06.151065Z"
        },
        "id": "rNX5LhPSJouG",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset, DatasetDict\n",
        "\n",
        "dataset = DatasetDict()\n",
        "dataset['train'] = load_dataset(\"mozilla-foundation/common_voice_12_0\", \"ar\", split=\"train[57%:]\", trust_remote_code=True)\n",
        "dataset['validation'] = load_dataset(\"mozilla-foundation/common_voice_12_0\", \"ar\", split=\"validation[90%:]\", trust_remote_code=True)\n",
        "dataset['test'] = load_dataset(\"mozilla-foundation/common_voice_12_0\", \"ar\", split=\"test[65%:]\", trust_remote_code=True)\n",
        "\n",
        "# Keep only audio and sentence columns\n",
        "columns_to_keep = ['audio', 'sentence']\n",
        "dataset = dataset.remove_columns([col for col in dataset['train'].column_names if col not in columns_to_keep])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Li3zZNa1JouH"
      },
      "source": [
        "## Dataset shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-06T15:35:07.811868Z",
          "iopub.status.busy": "2025-05-06T15:35:07.811570Z",
          "iopub.status.idle": "2025-05-06T15:35:07.816762Z",
          "shell.execute_reply": "2025-05-06T15:35:07.816053Z",
          "shell.execute_reply.started": "2025-05-06T15:35:07.811846Z"
        },
        "id": "E1AG9cLZMjCH",
        "outputId": "62019acf-0ce5-49df-e890-c895dc25d4c0",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['audio', 'sentence'],\n",
              "        num_rows: 12124\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['audio', 'sentence'],\n",
              "        num_rows: 1035\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['audio', 'sentence'],\n",
              "        num_rows: 3652\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xp9oA5SDJouI"
      },
      "source": [
        "## Filter and Normalize Text\n",
        "### - Text Cleaning and Normalization\n",
        "\n",
        "This step cleans the Arabic text by:\n",
        "\n",
        "- Removing diacritics and unwanted symbols  \n",
        "- Normalizing similar characters (e.g., \"Ø£\", \"Ø¥\", \"Ø¢\" â†’ \"Ø§\")  \n",
        "- Removing non-Arabic characters and extra whitespace\n",
        "\n",
        "This ensures that the text is consistent for model training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "c2d34a17b2eb457a81474863c8f3b10a",
            "b6f78e9c16f3444489fde57f838781ac",
            "5c284501815c4ec7a0313c76fed78e9c",
            "926c7c0a2c934a98a023a5c207032388",
            "9f17cecb7a98436981bf618f080062b6",
            "744afe8fb1ec478c9bcdd760e6dd06cb",
            "606366a976a04f09a786f3a88d92544c",
            "42d8e50307cf4937b77abdcc1e0f0fec",
            "304084216a774104aaaa61521daa29b7",
            "45e0c9d85b954f9b9b4a560719bc15be",
            "663ea13e2beb412fa95d282396f57107",
            "00ab9dbc56f245579ca851aa8880e12f"
          ]
        },
        "execution": {
          "iopub.execute_input": "2025-05-06T15:19:41.915295Z",
          "iopub.status.busy": "2025-05-06T15:19:41.914237Z",
          "iopub.status.idle": "2025-05-06T15:21:58.479286Z",
          "shell.execute_reply": "2025-05-06T15:21:58.478478Z",
          "shell.execute_reply.started": "2025-05-06T15:19:41.915268Z"
        },
        "id": "J82UGWBdMnwk",
        "outputId": "d6ce3721-7b98-4544-e5d8-958b2e933f3a",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "606366a976a04f09a786f3a88d92544c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/12124 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "42d8e50307cf4937b77abdcc1e0f0fec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/3624 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "304084216a774104aaaa61521daa29b7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/4173 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "45e0c9d85b954f9b9b4a560719bc15be",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/12124 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "663ea13e2beb412fa95d282396f57107",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/3624 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "00ab9dbc56f245579ca851aa8880e12f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/4173 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def filter_empty(example):\n",
        "    return example[\"sentence\"].strip() != \"\"\n",
        "\n",
        "def text_preprocessing(batch):\n",
        "    batch['sentence'] = re.sub(r'[\\u0617-\\u061A\\u064B-\\u0652]', '', batch['sentence'])\n",
        "    batch['sentence'] = re.sub(r'[^\\u0621-\\u063A\\u0641-\\u064A\\s]', '', batch['sentence'])\n",
        "    batch['sentence'] = re.sub(r'[Ø¥Ø£Ø¢Ø§]', 'Ø§', batch['sentence'])\n",
        "    batch['sentence'] = re.sub(r'Ù‰', 'ÙŠ', batch['sentence'])\n",
        "    batch['sentence'] = re.sub(r'Ø¤', 'Ùˆ', batch['sentence'])\n",
        "    batch['sentence'] = re.sub(r'Ø¦', 'ÙŠ', batch['sentence'])\n",
        "    batch['sentence'] = re.sub(r'Ø©', 'Ù‡', batch['sentence'])\n",
        "    batch['sentence'] = re.sub(r'\\s+', ' ', batch['sentence']).strip()\n",
        "    return batch\n",
        "\n",
        "dataset = dataset.filter(filter_empty)\n",
        "dataset = dataset.map(text_preprocessing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgNXeITKJouI"
      },
      "source": [
        "#  Load Whisper Model and Processor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "f145322e3ea24f0ab9c4140fed857d9a",
            "2cbb10d841464f9d86698df15a4b4ba8",
            "8537733aa3ca466e87e22166e287b353",
            "dc0c2d089bba432ca855dbf26b964192",
            "17fe4aa020004da282a6e552b51d47df",
            "429170db73654833bc57f58348b70da3",
            "7b9b726898244c09a63d5d983e1ebc1b",
            "2a13c9d01bc04a2fbd1a8f496e308e4d",
            "13fbf6c552234079a4e3161f76fea096",
            "b51373b298934bd882acaa613529b6d2",
            "a878e84efc684d28bc4aaad8ab4aab2e",
            "cd25c9380204483082806b2795217159",
            "15d8c19478d7458fa4a97bf0033f01e3",
            "fa99238d9a3345518145d30531d654d9",
            "c04c4b4098ff46929da1b085673c8f11",
            "d4df844b42714784a56cb90fe1dc719e",
            "4a0f620bd108432e8e0ce9366dfae86a",
            "089b79395f20405f80a0d8717fde136f",
            "f6aae97d0e7243ee8ffbb1eeadbd690d",
            "1c8921243a7e4973a15b3ee6b8abede4",
            "34455e63d8454409af2cdba26cda192c",
            "e0498f04d17d4ed9b01d83e9898fc260"
          ]
        },
        "execution": {
          "iopub.execute_input": "2025-05-06T15:32:57.609914Z",
          "iopub.status.busy": "2025-05-06T15:32:57.609602Z",
          "iopub.status.idle": "2025-05-06T15:33:26.860301Z",
          "shell.execute_reply": "2025-05-06T15:33:26.859607Z",
          "shell.execute_reply.started": "2025-05-06T15:32:57.609894Z"
        },
        "id": "CJ4q0hWPOqfA",
        "outputId": "83590564-f5e9-49bf-a659-98caf5545530",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-05-06 15:33:09.074542: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1746545589.259646      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1746545589.313556      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cd25c9380204483082806b2795217159",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/1.97k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "15d8c19478d7458fa4a97bf0033f01e3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/967M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa99238d9a3345518145d30531d654d9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/3.87k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c04c4b4098ff46929da1b085673c8f11",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/185k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d4df844b42714784a56cb90fe1dc719e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/283k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4a0f620bd108432e8e0ce9366dfae86a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/836k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "089b79395f20405f80a0d8717fde136f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.48M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f6aae97d0e7243ee8ffbb1eeadbd690d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1c8921243a7e4973a15b3ee6b8abede4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "34455e63d8454409af2cdba26cda192c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/34.6k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e0498f04d17d4ed9b01d83e9898fc260",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/2.19k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model base: model\n",
            "Model architecture: WhisperForConditionalGeneration\n",
            "Model size (parameters): 241.734912 M\n",
            "Tokenizer vocab size: 50258\n"
          ]
        }
      ],
      "source": [
        "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
        "\n",
        "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n",
        "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\", language=\"ar\", task=\"transcribe\")\n",
        "\n",
        "# Print basic model architecture info\n",
        "print(\"Model base:\", model.base_model_prefix)\n",
        "print(\"Model architecture:\", model.__class__.__name__)\n",
        "print(\"Model size (parameters):\", sum(p.numel() for p in model.parameters()) / 1e6, \"M\")\n",
        "\n",
        "# Print tokenizer info\n",
        "print(\"Tokenizer vocab size:\", processor.tokenizer.vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-06T09:07:53.835577Z",
          "iopub.status.busy": "2025-05-06T09:07:53.834281Z",
          "iopub.status.idle": "2025-05-06T09:07:53.844113Z",
          "shell.execute_reply": "2025-05-06T09:07:53.843428Z",
          "shell.execute_reply.started": "2025-05-06T09:07:53.835542Z"
        },
        "id": "GAX4cl9VJouJ",
        "outputId": "8a11b94e-2548-4b72-c4f1-65625229b839",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "WhisperForConditionalGeneration(\n",
              "  (model): WhisperModel(\n",
              "    (encoder): WhisperEncoder(\n",
              "      (conv1): Conv1d(80, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "      (conv2): Conv1d(768, 768, kernel_size=(3,), stride=(2,), padding=(1,))\n",
              "      (embed_positions): Embedding(1500, 768)\n",
              "      (layers): ModuleList(\n",
              "        (0-11): 12 x WhisperEncoderLayer(\n",
              "          (self_attn): WhisperSdpaAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (decoder): WhisperDecoder(\n",
              "      (embed_tokens): Embedding(51865, 768, padding_idx=50257)\n",
              "      (embed_positions): WhisperPositionalEmbedding(448, 768)\n",
              "      (layers): ModuleList(\n",
              "        (0-11): 12 x WhisperDecoderLayer(\n",
              "          (self_attn): WhisperSdpaAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): WhisperSdpaAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (proj_out): Linear(in_features=768, out_features=51865, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2LkJrb4JouJ"
      },
      "source": [
        "## Audio & Text Preprocessing\n",
        "### - Audio and Text Preprocessing: `prepare_dataset(batch)`\n",
        "\n",
        "This function processes each audio-text pair into model-ready inputs:\n",
        "\n",
        "1. Converts audio waveform into input features using Whisper's processor  \n",
        "2. Tokenizes the normalized text into label IDs  \n",
        "3. Returns `input_features` and `labels` ready for training\n",
        "\n",
        "This mapping is applied to the full dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "484cf0803e614a43a6720570221d5491",
            "0bd8d639a2164daf82540dfa7e6e855c",
            "51df993b0d30417eb07567ddc793fe3a"
          ]
        },
        "execution": {
          "iopub.execute_input": "2025-05-06T09:08:12.832722Z",
          "iopub.status.busy": "2025-05-06T09:08:12.832353Z",
          "iopub.status.idle": "2025-05-06T09:08:45.936439Z",
          "shell.execute_reply": "2025-05-06T09:08:45.93548Z",
          "shell.execute_reply.started": "2025-05-06T09:08:12.832683Z"
        },
        "id": "FfSC_ZDoJouJ",
        "outputId": "cdafd9dc-5c73-4fa6-a18c-277b23185483",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "484cf0803e614a43a6720570221d5491",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/282 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0bd8d639a2164daf82540dfa7e6e855c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/518 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "51df993b0d30417eb07567ddc793fe3a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/522 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import librosa  # Ensure you have librosa for resampling\n",
        "\n",
        "def prepare_dataset(batch):\n",
        "    audio = batch[\"audio\"]\n",
        "    # Resample audio from 48kHz to 16kHz (Whisper's expected sampling rate)\n",
        "    audio_resampled = librosa.resample(audio[\"array\"], orig_sr=audio[\"sampling_rate\"], target_sr=16000)\n",
        "    # Process the resampled audio with Whisper's feature extractor\n",
        "    inputs = processor(audio_resampled, sampling_rate=16000, return_tensors=\"pt\")\n",
        "    # Store input features and labels\n",
        "    batch[\"input_features\"] = inputs.input_features[0]\n",
        "    batch[\"labels\"] = processor.tokenizer(batch[\"sentence\"]).input_ids\n",
        "\n",
        "    return batch\n",
        "\n",
        "dataset = dataset.map(prepare_dataset, remove_columns=dataset[\"train\"].column_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-06T09:08:47.658625Z",
          "iopub.status.busy": "2025-05-06T09:08:47.658319Z",
          "iopub.status.idle": "2025-05-06T09:08:47.663495Z",
          "shell.execute_reply": "2025-05-06T09:08:47.662747Z",
          "shell.execute_reply.started": "2025-05-06T09:08:47.658603Z"
        },
        "id": "zyruMmvaJouK",
        "outputId": "5de8eb9a-67c5-40a8-bd20-544bde7155f9",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_features', 'labels'],\n",
              "        num_rows: 282\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['input_features', 'labels'],\n",
              "        num_rows: 518\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['input_features', 'labels'],\n",
              "        num_rows: 522\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjscO64YJouK"
      },
      "source": [
        "# Define Data Collator\n",
        "### - What is a Data Collator?\n",
        "\n",
        "The **data collator** is used to dynamically pad input and label sequences within each training batch.\n",
        "Since audio inputs and their corresponding tokenized labels can have variable lengths, the data collator:\n",
        "\n",
        "- Pads all `input_features` (audio representations) to the length of the longest in the batch.\n",
        "- Pads all `labels` (token IDs) to the length of the longest label sequence in the batch.\n",
        "- Ensures consistent tensor shapes for efficient training.\n",
        "\n",
        "This is essential for feeding batched data into the model correctly during training and evaluation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-06T09:09:02.0062Z",
          "iopub.status.busy": "2025-05-06T09:09:02.005937Z",
          "iopub.status.idle": "2025-05-06T09:09:02.011066Z",
          "shell.execute_reply": "2025-05-06T09:09:02.010443Z",
          "shell.execute_reply.started": "2025-05-06T09:09:02.006179Z"
        },
        "id": "uBj8bNgbO-Ji",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def data_collator(features):\n",
        "    input_features = [torch.tensor(f[\"input_features\"]) for f in features]\n",
        "    input_features = torch.nn.utils.rnn.pad_sequence(input_features, batch_first=True, padding_value=0)\n",
        "\n",
        "    labels = [torch.tensor(f[\"labels\"]) for f in features]\n",
        "    labels = torch.nn.utils.rnn.pad_sequence(\n",
        "        labels, batch_first=True, padding_value=processor.tokenizer.pad_token_id or -100\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"input_features\": input_features,\n",
        "        \"labels\": labels\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PD0yvvyaJouK"
      },
      "source": [
        "# Evaluation Metric (WER)\n",
        "\n",
        "**Word Error Rate (WER)** is the standard metric for evaluating speech recognition models.  \n",
        "It measures how many words were incorrectly predicted, and is calculated as:\n",
        "\n",
        "`[\n",
        "text{WER} = frac{S + D + I}{N}\n",
        "]`\n",
        "\n",
        "Where:\n",
        "- **S** = Substitutions  \n",
        "- **D** = Deletions  \n",
        "- **I** = Insertions  \n",
        "- **N** = Total words in the reference (ground truth)\n",
        "\n",
        "Lower WER means better transcription performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "252fe2bfa5af4bec89934399117756e1"
          ]
        },
        "execution": {
          "iopub.execute_input": "2025-05-06T09:09:06.041867Z",
          "iopub.status.busy": "2025-05-06T09:09:06.040995Z",
          "iopub.status.idle": "2025-05-06T09:09:07.336777Z",
          "shell.execute_reply": "2025-05-06T09:09:07.336252Z",
          "shell.execute_reply.started": "2025-05-06T09:09:06.041835Z"
        },
        "id": "48b1i4hxJouL",
        "outputId": "a72d4f14-8005-4cc0-e2a1-0197d57ba6bf",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "252fe2bfa5af4bec89934399117756e1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/4.49k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import evaluate\n",
        "wer_metric = evaluate.load('wer')\n",
        "def get_wer(reference, prediction):\n",
        "  wer_results = wer_metric.compute(predictions=predictions, references=references)\n",
        "  return wer_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqugaWEtJouL"
      },
      "source": [
        "# Define Training Arguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-06T09:09:23.524006Z",
          "iopub.status.busy": "2025-05-06T09:09:23.523278Z",
          "iopub.status.idle": "2025-05-06T09:09:23.56567Z",
          "shell.execute_reply": "2025-05-06T09:09:23.565083Z",
          "shell.execute_reply.started": "2025-05-06T09:09:23.523982Z"
        },
        "id": "DAEax0uQTmxA",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from transformers import Seq2SeqTrainingArguments\n",
        "from transformers import TrainerCallback\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./whisper-small-ar-finetuned\",\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=1,\n",
        "    eval_strategy=\"epoch\",  # No evaluation during training\n",
        "    save_strategy=\"epoch\",\n",
        "    num_train_epochs=3,\n",
        "    gradient_accumulation_steps=2,\n",
        "    fp16=True,\n",
        "    save_steps=500,\n",
        "    logging_steps=500,\n",
        "    logging_strategy=\"steps\",\n",
        "    learning_rate=1e-4,\n",
        "    warmup_steps=500,\n",
        "    save_total_limit=1,\n",
        "    push_to_hub=False,\n",
        "    report_to=\"none\",\n",
        "    load_best_model_at_end=False,\n",
        "    length_column_name=\"input_length\",\n",
        "    remove_unused_columns=False,\n",
        "    predict_with_generate=False,\n",
        "    eval_accumulation_steps=8,\n",
        ")\n",
        "\n",
        "\n",
        "class PrintLossCallback(TrainerCallback):\n",
        "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "        print(f\">>> Step {state.global_step}: {logs}\")\n",
        "\n",
        "\n",
        "class WEREvery2EpochsCallback(TrainerCallback):  ## * note -> I don't use this class because it still have OOM ERROR :'-(\n",
        "    def on_epoch_begin(self, args, state, control, **kwargs):\n",
        "        if state.epoch % 2 < 1e-6:\n",
        "            trainer.args.predict_with_generate = True\n",
        "        else:\n",
        "            trainer.args.predict_with_generate = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-3UHFClJouL"
      },
      "source": [
        "#  Create Trainer and Start Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-06T09:09:39.917911Z",
          "iopub.status.busy": "2025-05-06T09:09:39.917193Z",
          "iopub.status.idle": "2025-05-06T09:09:41.821253Z",
          "shell.execute_reply": "2025-05-06T09:09:41.820581Z",
          "shell.execute_reply.started": "2025-05-06T09:09:39.917888Z"
        },
        "id": "wPonwbMRW4Dg",
        "outputId": "2131ce85-dcd2-4bf2-bba3-51ffcd94def9",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_31/1950437651.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Seq2SeqTrainer(\n"
          ]
        }
      ],
      "source": [
        "from transformers import Seq2SeqTrainer\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    args=training_args,\n",
        "    model=model,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    eval_dataset=dataset[\"validation\"],\n",
        "    tokenizer=processor.tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    #compute_metrics = get_wer,\n",
        "    callbacks = [TrainerCallback()]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvYgxtXiJouM"
      },
      "source": [
        "## Training Progress"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "execution": {
          "iopub.execute_input": "2025-05-06T09:09:49.149584Z",
          "iopub.status.busy": "2025-05-06T09:09:49.14896Z",
          "iopub.status.idle": "2025-05-06T09:26:21.150319Z",
          "shell.execute_reply": "2025-05-06T09:26:21.149543Z",
          "shell.execute_reply.started": "2025-05-06T09:09:49.149562Z"
        },
        "id": "5Jm2TujkvSri",
        "outputId": "9ac2590d-c26b-47c6-901a-52c565dd944f",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "</style>\n",
              "<table id=\"T_a82a5\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th id=\"T_a82a5_level0_col0\" class=\"col_heading level0 col0\" >epoch</th>\n",
              "      <th id=\"T_a82a5_level0_col1\" class=\"col_heading level0 col1\" >train_loss</th>\n",
              "      <th id=\"T_a82a5_level0_col2\" class=\"col_heading level0 col2\" >eval_loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td id=\"T_a82a5_row0_col0\" class=\"data row0 col0\" >1</td>\n",
              "      <td id=\"T_a82a5_row0_col1\" class=\"data row0 col1\" >0.632600</td>\n",
              "      <td id=\"T_a82a5_row0_col2\" class=\"data row0 col2\" >0.695600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_a82a5_row1_col0\" class=\"data row1 col0\" >2</td>\n",
              "      <td id=\"T_a82a5_row1_col1\" class=\"data row1 col1\" >0.264100</td>\n",
              "      <td id=\"T_a82a5_row1_col2\" class=\"data row1 col2\" >0.626800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_a82a5_row2_col0\" class=\"data row2 col0\" >3</td>\n",
              "      <td id=\"T_a82a5_row2_col1\" class=\"data row2 col1\" >0.129100</td>\n",
              "      <td id=\"T_a82a5_row2_col2\" class=\"data row2 col2\" >0.552900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x792028830790>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-05T22:08:40.522401Z",
          "iopub.status.busy": "2025-05-05T22:08:40.52158Z",
          "iopub.status.idle": "2025-05-05T22:08:40.525826Z",
          "shell.execute_reply": "2025-05-05T22:08:40.525159Z",
          "shell.execute_reply.started": "2025-05-05T22:08:40.522376Z"
        },
        "id": "eRgY6pgBJouM",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "trainer.args.predict_with_generate = True # Make sure generation is enable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqaGrFeLyBzV"
      },
      "source": [
        "# Save Fine-Tuned Model and Processor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKzBXZL-yBzV",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Save the fine-tuned Whisper model and processor\n",
        "model_path = \"./whisper-arabic-finetuned-best\"\n",
        "trainer.save_model(model_path)\n",
        "processor.save_pretrained(model_path)\n",
        "\n",
        "print(f\"\\n >>> Model and processor saved to: {model_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "em1k9kPDyBzV"
      },
      "source": [
        "# Final Evaluation on Training Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbXNAkkQJouN",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "print(\"----------------------\")\n",
        "predictions = trainer.predict(dataset[\"train\"])\n",
        "pred_str = processor.batch_decode(predictions.predictions, skip_special_tokens=True)\n",
        "wer_metric = evaluate.load(\"wer\")\n",
        "\n",
        "print(\"----------------------\")\n",
        "\n",
        "# Decode references (labels)\n",
        "label_ids = predictions.label_ids\n",
        "label_ids[label_ids == -100] = processor.tokenizer.pad_token_id  # Masking\n",
        "label_str = processor.batch_decode(label_ids, skip_special_tokens=True)\n",
        "wers = [wer_metric.compute(predictions=[p], references=[r]) for p, r in zip(pred_str, label_str)]\n",
        "df_train = pd.DataFrame({\n",
        "    \"reference\": label_str,\n",
        "    \"prediction\": pred_str,\n",
        "    \"wer\": wers\n",
        "})\n",
        "\n",
        "df_train.to_csv(\"wer_train.csv\", index=False)\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ca1m3eagJouN",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print(\"\\n--- Final Evaluation on Training Set ---\\n\")\n",
        "print(f'\\n TRAINING WER : {df_train['wer'].mean()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWqDf0m-JouO"
      },
      "source": [
        "# Final Evaluation on Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTr6LBySJouO",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print(\"----------------------\")\n",
        "predictions = trainer.predict(dataset[\"validation\"])\n",
        "pred_str = processor.batch_decode(predictions.predictions, skip_special_tokens=True)\n",
        "wer_metric = evaluate.load(\"wer\")\n",
        "\n",
        "print(\"----------------------\")\n",
        "\n",
        "# Decode references (labels)\n",
        "label_ids = predictions.label_ids\n",
        "label_ids[label_ids == -100] = processor.tokenizer.pad_token_id  # Masking\n",
        "label_str = processor.batch_decode(label_ids, skip_special_tokens=True)\n",
        "wers = [wer_metric.compute(predictions=[p], references=[r]) for p, r in zip(pred_str, label_str)]\n",
        "df_valid = pd.DataFrame({\n",
        "    \"reference\": label_str,\n",
        "    \"prediction\": pred_str,\n",
        "    \"wer\": wers\n",
        "})\n",
        "\n",
        "df_valid.to_csv(\"wer_valid.csv\", index=False)\n",
        "df_valid.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMOYXMXnyBzV",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print(\"\\n--- Final Evaluation on Validation Set ---\\n\")\n",
        "print(f'\\n VALIDATION WER : {df_valid['wer'].mean()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YNNqSwyJouP"
      },
      "source": [
        "#  Final Evaluation on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oB2QVtc_JouP",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "print(\"----------------------\")\n",
        "predictions = trainer.predict(dataset[\"test\"])\n",
        "pred_str = processor.batch_decode(predictions.predictions, skip_special_tokens=True)\n",
        "wer_metric = evaluate.load(\"wer\")\n",
        "\n",
        "print(\"----------------------\")\n",
        "\n",
        "# Decode references (labels)\n",
        "label_ids = predictions.label_ids\n",
        "label_ids[label_ids == -100] = processor.tokenizer.pad_token_id  # Masking\n",
        "label_str = processor.batch_decode(label_ids, skip_special_tokens=True)\n",
        "wers = [wer_metric.compute(predictions=[p], references=[r]) for p, r in zip(pred_str, label_str)]\n",
        "df_test = pd.DataFrame({\n",
        "    \"reference\": label_str,\n",
        "    \"prediction\": pred_str,\n",
        "    \"wer\": wers\n",
        "})\n",
        "\n",
        "df_test.to_csv(\"wer_test.csv\", index=False)\n",
        "df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YcEAeCEuyBzW",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print(\"\\n--- Final Evaluation on Test Set ---\\n\")\n",
        "print(f'\\n TEST WER : {df_test['wer'].mean()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxOKHq9TJouV"
      },
      "source": [
        "# Load Saved Model For Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jL1RiVdPJouV",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from transformers import WhisperForConditionalGeneration, WhisperProcessor\n",
        "\n",
        "# Load the fine-tuned model and processor\n",
        "model = WhisperForConditionalGeneration.from_pretrained(model_path).to(\"cuda\")\n",
        "processor = WhisperProcessor.from_pretrained(model_path)\n",
        "\n",
        "print(\"... Model and processor successfully reloaded for inference.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jhowu0kEJouV"
      },
      "source": [
        "# INFERENCE FUNCTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0gi-duGJouV",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def transcribe_audio(audio_array, sampling_rate=16000):\n",
        "    inputs = processor(audio_array, sampling_rate=sampling_rate, return_tensors=\"pt\")\n",
        "    input_features = inputs.input_features.to(\"cuda\")\n",
        "\n",
        "    # Generate tokens\n",
        "    predicted_ids = model.generate(input_features)\n",
        "\n",
        "    # Decode to text\n",
        "    transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n",
        "    return transcription\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UF82446BJouW",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# **--------------------- The End --------------------**\n",
        "#Code by Mohammed Mossad"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 31011,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
